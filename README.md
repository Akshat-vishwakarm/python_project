Project Title: Dino T-Rex Game Control Using Hand Gestures
Description:
This project is a Python-based implementation that allows users to control the Google Chrome Dino T-Rex game using hand gestures. It utilizes computer vision techniques to detect and interpret hand gestures through a webcam. The primary functionality includes recognizing an open palm gesture to make the Dino jump, creating a unique and interactive way to play the game.

Key Features:
Hand Gesture Recognition:

Utilizes a webcam to capture real-time video feed.
Processes the video feed to detect an open palm gesture.
Computer Vision Techniques:

Leverages libraries like OpenCV for image processing.
Uses MediaPipe or a similar framework for hand tracking and gesture recognition.
Game Control Integration:

Simulates a keyboard input (Spacebar) when an open palm gesture is detected, making the Dino jump.
Seamless Gameplay:

Offers real-time gesture recognition with minimal lag.
Ensures accurate detection to enhance the gaming experience.
Customizable Settings:

Adjustable sensitivity for gesture detection.
Option to calibrate the gesture model for different hand sizes and shapes.
Technologies Used:
Python: Programming language for developing the application.
OpenCV: For image processing and real-time video analysis.
MediaPipe: For efficient hand tracking and gesture recognition.
PyAutoGUI: To simulate keyboard events for game control.
Steps to Use:
Launch the program and allow webcam access.
Open the Google Chrome Dino T-Rex game.
Position your hand in front of the webcam.
Perform an open palm gesture to make the Dino jump and avoid obstacles.
Learning Outcomes:
Hands-on experience with Python libraries for computer vision.
Understanding gesture recognition and its real-world applications.
Integration of computer vision with simulated keyboard events for game control.
